# Copyright (c) Nex-AGI. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
LLM Interface and Query Generation System for Gyrfalcon v3 Pipeline

This module handles communication with LLM services and generates queries
based on problem type traces, personas, and framework metadata.
"""

import copy
import json
import logging
import os
import re
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

import openai

from frameworks.framework_manager import FrameworkPersona
from llm_interface.agents import (
    AgentContext,
    FileAugmentationAgent,
    FileRequirementAgent,
    FileSystemAgent,
    QuerySynthesisAgent,
    RewriteAgent,
    RouterAgent,
    URLProcessingAgent,
)
from llm_interface.agents.fuzzifier_agent import FuzzifierAgent
from llm_interface.agents.web_research_agent import WebResearchAgent
from problem_type_tree import ProblemTypeNode, TagTrace

logger = logging.getLogger(__name__)


@dataclass
class GeneratedQuery:
    """Represents a generated query with metadata"""

    content: str
    difficulty: str
    context: Dict[str, Any]
    metadata: Dict[str, Any]


@dataclass
class QueryGenerationResult:
    """Result of query generation including queries (no new tags in new design)"""

    queries: List[GeneratedQuery]
    trace_context: List[str]
    problem_type: str  # The selected problem type
    generation_metadata: Dict[str, Any]


class LLMClient:
    """
    Client for communicating with LLM services using OpenAI API.
    """

    def __init__(
        self,
        base_url: str,
        api_key: str,
        model_name: str,
        temperature: float = 0.7,
        max_tokens: int = 2048,
        timeout: float = 600.0,
        max_retries: int = 3,
    ):
        self.client = openai.OpenAI(
            base_url=base_url, api_key=api_key, timeout=timeout, max_retries=max_retries
        )
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens

    def generate_completion(
        self, prompt: str, system_prompt: Optional[str] = None
    ) -> str:
        """
        Generate a completion from the LLM.
        """
        messages = []

        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        messages.append({"role": "user", "content": prompt})

        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
            )

            content = response.choices[0].message.content

            # Debug: Check if content is None or empty
            if not content:
                logger.error(f"LLM returned empty content! Response object: {response}")
                logger.error(f"Choices: {response.choices}")
                logger.error(
                    f"Message: {response.choices[0].message if response.choices else 'No choices'}"
                )
                return ""

            logger.debug(f"LLM response length: {len(content)} characters")
            return content

        except Exception as e:
            logger.error(f"Error generating completion: {e}")
            raise


class PromptTemplateManager:
    """
    Manages prompt templates for query generation.
    """

    def __init__(self):
        self.templates = {
            "persona_evaluation_english": """You are an expert at evaluating whether a user persona is suitable for asking questions about a specific problem type.

Given:
- User Persona: {persona}
- Problem Type: "{problem_type}"

Task: Evaluate if this persona would naturally ask questions about this problem type.

Respond ONLY with one of these exact phrases:
- "SUITABLE" - if the persona would naturally ask about this problem type
- "NOT_SUITABLE" - if the persona would NOT naturally ask about this problem type

Consider:
1. Does the persona's background/role/expertise align with this problem type?
2. Would someone with this persona have legitimate reasons to ask about this problem type?
3. Is there a natural fit between the persona's needs and this problem type?

Your response:""",
            "persona_evaluation_chinese": """ä½ æ˜¯è¯„ä¼°ç”¨æˆ·è§’è‰²æ˜¯å¦é€‚åˆè¯¢é—®ç‰¹å®šé—®é¢˜ç±»å‹çš„ä¸“å®¶ã€‚

ç»™å®šä¿¡æ¯ï¼š
- ç”¨æˆ·è§’è‰²: {persona}
- é—®é¢˜ç±»å‹: "{problem_type}"

ä»»åŠ¡ï¼šè¯„ä¼°è¿™ä¸ªç”¨æˆ·è§’è‰²æ˜¯å¦ä¼šè‡ªç„¶åœ°è¯¢é—®å…³äºè¿™ä¸ªé—®é¢˜ç±»å‹çš„é—®é¢˜ã€‚

è¯·åªå›ç­”ä»¥ä¸‹çŸ­è¯­ä¹‹ä¸€ï¼š
- "SUITABLE" - å¦‚æœè¯¥è§’è‰²ä¼šè‡ªç„¶åœ°è¯¢é—®è¿™ä¸ªé—®é¢˜ç±»å‹
- "NOT_SUITABLE" - å¦‚æœè¯¥è§’è‰²ä¸ä¼šè‡ªç„¶åœ°è¯¢é—®è¿™ä¸ªé—®é¢˜ç±»å‹

è€ƒè™‘å› ç´ ï¼š
1. è§’è‰²çš„èƒŒæ™¯/èŒä½/ä¸“ä¸šçŸ¥è¯†æ˜¯å¦ä¸æ­¤é—®é¢˜ç±»å‹ä¸€è‡´ï¼Ÿ
2. å…·æœ‰æ­¤è§’è‰²çš„äººæ˜¯å¦æœ‰åˆç†çš„ç†ç”±è¯¢é—®æ­¤é—®é¢˜ç±»å‹ï¼Ÿ
3. è§’è‰²çš„éœ€æ±‚ä¸æ­¤é—®é¢˜ç±»å‹ä¹‹é—´æ˜¯å¦æœ‰è‡ªç„¶çš„å¥‘åˆï¼Ÿ

ä½ çš„å›ç­”ï¼š""",
            "persona_rewriting_english_simple": """You are an expert at adapting user personas to make them suitable for asking questions about specific problem types.

Given:
- Original Persona: {persona}
- Problem Type: "{problem_type}"

Task: Rewrite the persona in THIRD PERSON (describing "a person who...") to make it suitable for asking about this problem type. Keep it CONCISE and natural.

Requirements:
1. Use THIRD PERSON description (e.g., "A researcher who..." NOT "I am...")
2. Keep it SHORT and focused (1-2 sentences maximum)
3. Preserve key attributes (role, constraints)
4. Adjust context to fit the problem type
5. Write in the same language as the original

Output ONLY the rewritten persona, nothing else.

Rewritten persona:""",
            "persona_rewriting_english_moderate": """You are an expert at adapting user personas to make them suitable for asking questions about specific problem types.

Given:
- Original Persona: {persona}
- Problem Type: "{problem_type}"

Task: Rewrite the persona in THIRD PERSON (describing "a person who...") to make it suitable for asking about this problem type. Use moderate detail.

Requirements:
1. Use THIRD PERSON description (e.g., "A professor who..." NOT "I...")
2. Keep it CONCISE (2-3 sentences)
3. Preserve core characteristics (career stage, resources, work context)
4. Adjust situation to align with the problem type
5. Write naturally in the same language as the original

Output ONLY the rewritten persona, nothing else.

Rewritten persona:""",
            "persona_rewriting_english_detailed": """You are an expert at adapting user personas to make them suitable for asking questions about specific problem types.

Given:
- Original Persona: {persona}
- Problem Type: "{problem_type}"

Task: Rewrite the persona in THIRD PERSON (describing "a person who...") to make it suitable for asking about this problem type. Include relevant details.

Requirements:
1. Use THIRD PERSON description (e.g., "A senior researcher who..." NOT "I am...")
2. Keep it FOCUSED but informative (3-4 sentences)
3. Preserve all key attributes (role, expertise, resources, constraints, collaboration context)
4. Adjust goals and situation to fit the problem type
5. Maintain natural flow in the same language as the original

Output ONLY the rewritten persona, nothing else.

Rewritten persona:""",
            "persona_rewriting_chinese_simple": """ä½ æ˜¯ä¸€ä¸ªå°†ç”¨æˆ·è§’è‰²è°ƒæ•´ä¸ºé€‚åˆè¯¢é—®ç‰¹å®šé—®é¢˜ç±»å‹çš„ä¸“å®¶ã€‚

ç»™å®šä¿¡æ¯ï¼š
- åŸå§‹è§’è‰²: {persona}
- é—®é¢˜ç±»å‹: "{problem_type}"

ä»»åŠ¡ï¼šç”¨ç¬¬ä¸‰äººç§°ï¼ˆæè¿°"ä¸€ä¸ª...çš„äºº"ï¼‰é‡å†™è¿™ä¸ªè§’è‰²ï¼Œä½¿å…¶é€‚åˆè¯¢é—®è¿™ä¸ªé—®é¢˜ç±»å‹ã€‚ä¿æŒç®€æ´è‡ªç„¶ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨ç¬¬ä¸‰äººç§°æè¿°ï¼ˆä¾‹å¦‚ï¼š"ä¸€ä½ç ”ç©¶å‘˜..." è€Œä¸æ˜¯ "æˆ‘æ˜¯..."ï¼‰
2. ä¿æŒç®€çŸ­èšç„¦ï¼ˆæœ€å¤š1-2å¥è¯ï¼‰
3. ä¿ç•™å…³é”®å±æ€§ï¼ˆè§’è‰²ã€é™åˆ¶ï¼‰
4. è°ƒæ•´æƒ…å¢ƒä»¥ç¬¦åˆé—®é¢˜ç±»å‹
5. ä½¿ç”¨ä¸åŸå§‹è§’è‰²ç›¸åŒçš„è¯­è¨€

åªè¾“å‡ºé‡å†™åçš„è§’è‰²æ–‡æœ¬ã€‚

é‡å†™åçš„è§’è‰²ï¼š""",
            "persona_rewriting_chinese_moderate": """ä½ æ˜¯ä¸€ä¸ªå°†ç”¨æˆ·è§’è‰²è°ƒæ•´ä¸ºé€‚åˆè¯¢é—®ç‰¹å®šé—®é¢˜ç±»å‹çš„ä¸“å®¶ã€‚

ç»™å®šä¿¡æ¯ï¼š
- åŸå§‹è§’è‰²: {persona}
- é—®é¢˜ç±»å‹: "{problem_type}"

ä»»åŠ¡ï¼šç”¨ç¬¬ä¸‰äººç§°ï¼ˆæè¿°"ä¸€ä¸ª...çš„äºº"ï¼‰é‡å†™è¿™ä¸ªè§’è‰²ï¼Œä½¿å…¶é€‚åˆè¯¢é—®è¿™ä¸ªé—®é¢˜ç±»å‹ã€‚ä½¿ç”¨é€‚åº¦çš„ç»†èŠ‚ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨ç¬¬ä¸‰äººç§°æè¿°ï¼ˆä¾‹å¦‚ï¼š"ä¸€ä½æ•™æˆ..." è€Œä¸æ˜¯ "æˆ‘..."ï¼‰
2. ä¿æŒç®€æ´ï¼ˆ2-3å¥è¯ï¼‰
3. ä¿ç•™æ ¸å¿ƒç‰¹å¾ï¼ˆèŒä¸šé˜¶æ®µã€èµ„æºã€å·¥ä½œç¯å¢ƒï¼‰
4. è°ƒæ•´æƒ…å†µä»¥ä¸é—®é¢˜ç±»å‹å¯¹é½
5. ä½¿ç”¨ä¸åŸå§‹è§’è‰²ç›¸åŒçš„è¯­è¨€è‡ªç„¶ä¹¦å†™

åªè¾“å‡ºé‡å†™åçš„è§’è‰²æ–‡æœ¬ã€‚

é‡å†™åçš„è§’è‰²ï¼š""",
            "persona_rewriting_chinese_detailed": """ä½ æ˜¯ä¸€ä¸ªå°†ç”¨æˆ·è§’è‰²è°ƒæ•´ä¸ºé€‚åˆè¯¢é—®ç‰¹å®šé—®é¢˜ç±»å‹çš„ä¸“å®¶ã€‚

ç»™å®šä¿¡æ¯ï¼š
- åŸå§‹è§’è‰²: {persona}
- é—®é¢˜ç±»å‹: "{problem_type}"

ä»»åŠ¡ï¼šç”¨ç¬¬ä¸‰äººç§°ï¼ˆæè¿°"ä¸€ä¸ª...çš„äºº"ï¼‰é‡å†™è¿™ä¸ªè§’è‰²ï¼Œä½¿å…¶é€‚åˆè¯¢é—®è¿™ä¸ªé—®é¢˜ç±»å‹ã€‚åŒ…å«ç›¸å…³ç»†èŠ‚ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨ç¬¬ä¸‰äººç§°æè¿°ï¼ˆä¾‹å¦‚ï¼š"ä¸€ä½èµ„æ·±ç ”ç©¶å‘˜..." è€Œä¸æ˜¯ "æˆ‘æ˜¯..."ï¼‰
2. ä¿æŒèšç„¦ä½†ä¿¡æ¯ä¸°å¯Œï¼ˆ3-4å¥è¯ï¼‰
3. ä¿ç•™æ‰€æœ‰å…³é”®å±æ€§ï¼ˆè§’è‰²ã€ä¸“é•¿ã€èµ„æºã€é™åˆ¶ã€åˆä½œç¯å¢ƒï¼‰
4. è°ƒæ•´ç›®æ ‡å’Œæƒ…å†µä»¥é€‚åº”é—®é¢˜ç±»å‹
5. ä½¿ç”¨ä¸åŸå§‹è§’è‰²ç›¸åŒçš„è¯­è¨€ä¿æŒè‡ªç„¶æµç•…

åªè¾“å‡ºé‡å†™åçš„è§’è‰²æ–‡æœ¬ã€‚

é‡å†™åçš„è§’è‰²ï¼š""",
            "query_generation_english": """You are an expert at generating diverse, high-quality queries for agent frameworks based on specific contexts.

Given:
- User Persona: {persona}
- Selected Problem Type: "{problem_type}"
{framework_description_block}{search_context_block}

Generate exactly 3 distinct queries with different difficulty levels (easy, medium, hard) that:
1. Are posed from the perspective of the given persona (as if this user is asking the question)
2. Are specifically designed for the selected problem type: "{problem_type}"
3. Are realistic and actionable
4. Vary significantly in complexity and scope
5. Are COMPLETE, self-contained tasks that can be executed from scratch without requiring any previously completed work or unavailable information
6. **Have DIVERSE questioning styles and formats** - avoid using the same sentence structure or phrasing pattern for all queries

âš ï¸ CRITICAL QUERY REQUIREMENTS:
- Each query must be a standalone task that provides ALL necessary context and information
- Do NOT create queries that depend on "previous analysis", "existing data", "prior work", or "already established" anything
- Do NOT use phrases like "continue the analysis", "build upon", "expand the previous", "update the existing"
- Each query should start fresh and include all required background information within the query itself
- All queries must be appropriate for the problem type: "{problem_type}"

ğŸ¨ STYLE DIVERSITY REQUIREMENTS:
- Use DIFFERENT questioning formats: direct questions
- Vary sentence structures: some queries can be short and direct, others can be detailed with context
- Mix formal and informal tones when appropriate to the persona

ğŸš« ABSOLUTELY FORBIDDEN - DO NOT include ANY of the following in your queries:
- Any framework names whatsoever
- Tag trace paths or arrow symbols (e.g., "A â†’ B â†’ C")
- Problem type labels as metadata tags (e.g., "(æŸæŸåˆ†æ)", "(problem type: XXX)")
- Any references to "tag trace", "problem type context", or framework configuration
- Parenthetical labels showing classification

âœ… YOUR QUERIES MUST BE:
- Natural questions that a real user would ask
- Free from any framework/system metadata
- Written as if the user knows nothing about the underlying classification system
- Stylistically diverse in both format and tone

âš ï¸ FORMAT REQUIREMENTS - Must strictly use asterisks:

**QUERIES:**
**EASY:** [Your easy query here]
**MEDIUM:** [Your medium query here]
**HARD:** [Your hard query here]

Note: You MUST use double asterisks ** around labels. Do not omit them!

Ensure each query is complete, specific, and appropriate for the given difficulty level and problem type.""",
            "query_generation_chinese": """ä½ æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºæ™ºèƒ½ä½“æ¡†æ¶ç”Ÿæˆå¤šæ ·åŒ–ã€é«˜è´¨é‡æŸ¥è¯¢çš„ä¸“å®¶ï¼Œèƒ½å¤ŸåŸºäºç‰¹å®šä¸Šä¸‹æ–‡ç”Ÿæˆç›¸å…³çš„æŸ¥è¯¢ä»»åŠ¡ã€‚

ç»™å®šä¿¡æ¯ï¼š
- ç”¨æˆ·è§’è‰²: {persona}
- é€‰å®šçš„é—®é¢˜ç±»å‹: "{problem_type}"
{framework_description_block}{search_context_block}

è¯·ç”Ÿæˆ3ä¸ªä¸åŒéš¾åº¦çº§åˆ«ï¼ˆç®€å•ã€ä¸­ç­‰ã€å›°éš¾ï¼‰çš„æˆªç„¶ä¸åŒçš„æŸ¥è¯¢ï¼Œè¿™äº›æŸ¥è¯¢éœ€è¦ï¼š
1. ä»ç»™å®šç”¨æˆ·çš„è§†è§’æå‡ºï¼ˆå°±åƒè¿™ä¸ªç”¨æˆ·åœ¨æé—®ï¼‰
2. ä¸“é—¨é’ˆå¯¹é€‰å®šçš„é—®é¢˜ç±»å‹: "{problem_type}"
3. åˆ‡å®å¯è¡Œä¸”å…·æœ‰å¯æ“ä½œæ€§
4. åœ¨å¤æ‚æ€§å’ŒèŒƒå›´ä¸Šæœ‰æ˜¾è‘—å·®å¼‚
5. æ˜¯å®Œæ•´ã€ç‹¬ç«‹çš„ä»»åŠ¡ï¼Œå¯ä»¥ä»é›¶å¼€å§‹æ‰§è¡Œï¼Œæ— éœ€ä¾èµ–ä»»ä½•å·²å®Œæˆçš„å·¥ä½œæˆ–ä¸å¯è·å¾—çš„ä¿¡æ¯
6. **å…·æœ‰å¤šæ ·åŒ–çš„æé—®é£æ ¼å’Œæ ¼å¼** - é¿å…æ‰€æœ‰æŸ¥è¯¢ä½¿ç”¨ç›¸åŒçš„å¥å¼ç»“æ„æˆ–è¡¨è¾¾æ¨¡å¼

âš ï¸ æŸ¥è¯¢å…³é”®è¦æ±‚ï¼š
- æ¯ä¸ªæŸ¥è¯¢å¿…é¡»æ˜¯ç‹¬ç«‹ä»»åŠ¡ï¼Œæä¾›æ‰€æœ‰å¿…è¦çš„ä¸Šä¸‹æ–‡å’Œä¿¡æ¯
- ä¸è¦åˆ›å»ºä¾èµ–"ä¹‹å‰çš„åˆ†æ"ã€"ç°æœ‰æ•°æ®"ã€"å…ˆå‰å·¥ä½œ"æˆ–"å·²å»ºç«‹"å†…å®¹çš„æŸ¥è¯¢
- ä¸è¦ä½¿ç”¨"ç»§ç»­åˆ†æ"ã€"åŸºäº"ã€"æ‰©å±•ä¹‹å‰çš„"ã€"æ›´æ–°ç°æœ‰çš„"ç­‰è¡¨è¿°
- æ¯ä¸ªæŸ¥è¯¢éƒ½åº”ä»å¤´å¼€å§‹ï¼Œåœ¨æŸ¥è¯¢æœ¬èº«å†…åŒ…å«æ‰€æœ‰å¿…éœ€çš„èƒŒæ™¯ä¿¡æ¯
- æ‰€æœ‰æŸ¥è¯¢éƒ½å¿…é¡»é€‚ç”¨äºé—®é¢˜ç±»å‹: "{problem_type}"

ğŸ¨ é£æ ¼å¤šæ ·æ€§è¦æ±‚ï¼š
- ä½¿ç”¨ä¸åŒçš„æé—®æ ¼å¼
- å˜æ¢å¥å¼ç»“æ„ï¼šæœ‰çš„æŸ¥è¯¢å¯ä»¥ç®€çŸ­ç›´æ¥ï¼Œæœ‰çš„å¯ä»¥è¯¦ç»†é™„å¸¦ä¸Šä¸‹æ–‡
- æ ¹æ®è§’è‰²ç‰¹ç‚¹é€‚å½“æ··åˆæ­£å¼å’Œéæ­£å¼è¯­æ°”

ğŸš« ç»å¯¹ç¦æ­¢ - æŸ¥è¯¢ä¸­ä¸å¾—åŒ…å«ä»¥ä¸‹ä»»ä½•å†…å®¹ï¼š
- ä»»ä½•æ¡†æ¶çš„åç§°
- æ ‡ç­¾è½¨è¿¹è·¯å¾„æˆ–ç®­å¤´ç¬¦å·ï¼ˆå¦‚ "A â†’ B â†’ C"ï¼‰
- ä½œä¸ºå…ƒæ•°æ®æ ‡ç­¾çš„é—®é¢˜ç±»å‹ï¼ˆå¦‚ "(æŸæŸåˆ†æ)"ã€"(é—®é¢˜ç±»å‹: XXX)"ï¼‰
- ä»»ä½•æåŠ "tag trace"ã€"æ ‡ç­¾è½¨è¿¹"ã€"é—®é¢˜ç±»å‹ä¸Šä¸‹æ–‡" æˆ–æ¡†æ¶é…ç½®çš„å†…å®¹
- æ˜¾ç¤ºåˆ†ç±»çš„æ‹¬å·æ ‡ç­¾

âœ… ä½ çš„æŸ¥è¯¢å¿…é¡»ï¼š
- æ˜¯çœŸå®ç”¨æˆ·ä¼šæå‡ºçš„è‡ªç„¶é—®é¢˜
- ä¸å«ä»»ä½•æ¡†æ¶/ç³»ç»Ÿå…ƒæ•°æ®
- å°±åƒç”¨æˆ·å®Œå…¨ä¸çŸ¥é“åº•å±‚åˆ†ç±»ç³»ç»Ÿä¸€æ ·æ’°å†™
- åœ¨æ ¼å¼å’Œè¯­æ°”ä¸Šå…·æœ‰é£æ ¼å¤šæ ·æ€§

âš ï¸ æ ¼å¼è¦æ±‚ - å¿…é¡»ä¸¥æ ¼ä½¿ç”¨æ˜Ÿå·æ ‡è®°ï¼š

**æŸ¥è¯¢ä»»åŠ¡:**
**ç®€å•:** [ä½ çš„ç®€å•æŸ¥è¯¢ä»»åŠ¡]
**ä¸­ç­‰:** [ä½ çš„ä¸­ç­‰æŸ¥è¯¢ä»»åŠ¡]
**å›°éš¾:** [ä½ çš„å›°éš¾æŸ¥è¯¢ä»»åŠ¡]

æ³¨æ„ï¼šå¿…é¡»ä½¿ç”¨ä¸¤ä¸ªæ˜Ÿå· ** åŒ…å›´æ ‡ç­¾ï¼Œä¸è¦é—æ¼æ˜Ÿå·ï¼

ç¡®ä¿æ¯ä¸ªæŸ¥è¯¢å®Œæ•´ã€å…·ä½“ï¼Œä¸”é€‚åˆç»™å®šçš„éš¾åº¦çº§åˆ«å’Œé—®é¢˜ç±»å‹ã€‚""",
            "file_requirement_english": """You are a classifier that determines whether a user query explicitly requires files provided by the system.\n\nQuery:\n{query}\n\nRespond strictly in JSON with the following schema:\n{{\n  \"requires_files\": <true or false>,\n  \"reason\": \"<short explanation>\",\n  \"required_items\": [\"<item description>\", ...]\n}}\n\nMark requires_files as true only when the user clearly expects system-provided attachments or files. Otherwise, return false and an empty list.""",
            "file_requirement_chinese": """ä½ æ˜¯ä¸€ååˆ¤æ–­æŸ¥è¯¢æ˜¯å¦æ˜ç¡®éœ€è¦ç³»ç»Ÿæä¾›æ–‡ä»¶çš„åˆ†ç±»å™¨ã€‚\n\næŸ¥è¯¢ï¼š\n{query}\n\nè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ¨¡å¼è¾“å‡ºï¼š\n{{\n  \"requires_files\": <true æˆ– false>,\n  \"reason\": \"<ç®€çŸ­è¯´æ˜>\",\n  \"required_items\": [\"<æ–‡ä»¶éœ€æ±‚æè¿°>\", ...]\n}}\n\nåªæœ‰åœ¨æŸ¥è¯¢æ˜ç¡®è¦æ±‚ç³»ç»Ÿé™„å¸¦æ–‡ä»¶æ—¶ï¼Œæ‰å°† requires_files è®¾ä¸º trueï¼›å¦åˆ™è¿”å› false å’Œç©ºåˆ—è¡¨ã€‚""",
            "file_plan_english": """You are planning support files for an assistant. The assistant will provide local files when necessary.\n\nQuery:\n{query}\nRequested items (if any):\n{required_items}\n\nReturn a JSON object:{{\n  \"directory_name\": \"<short descriptive slug for the download folder>\",\n  \"files\": [\n    {{\"description\": \"<what the file contains>\", \"url\": \"<direct HTTPS download URL>\"}},\n    ...\n  ]\n}}\n\nSTRICT REQUIREMENTS:\n- Supply directory_name as a concise kebab-case summary (letters, numbers, hyphen only).\n- Every \"url\" MUST start with https:// and be publicly accessible.\n- Do NOT use http:// even if it exists; omit entries without an https variant.\n- Do NOT return data:, file:, ftp:, or any other scheme.\n- Omit entries you cannot satisfy.\n- Use an empty list if no files are required.""",
            "file_plan_chinese": """ä½ è´Ÿè´£ä¸ºåŠ©æ‰‹è§„åˆ’éœ€è¦æä¾›çš„æ”¯æŒæ–‡ä»¶ã€‚\n\næŸ¥è¯¢ï¼š\n{query}\nè‹¥æœ‰æ˜ç¡®éœ€æ±‚ï¼š\n{required_items}\n\nè¯·è¿”å› JSONï¼š{{\n  \"directory_name\": \"<ä¸‹è½½æ–‡ä»¶å¤¹çš„ç®€çŸ­è¯´æ˜ï¼ˆkebab-caseï¼‰>\",\n  \"files\": [\n    {{\"description\": \"<æ–‡ä»¶è¯´æ˜>\", \"url\": \"<å¯ç›´æ¥ä¸‹è½½çš„ HTTPS é“¾æ¥>\"}},\n    ...\n  ]\n}}\n\nä¸¥æ ¼è¦æ±‚ï¼š\n- directory_name è¯·ä½¿ç”¨ç®€æ´çš„è¿å­—ç¬¦å‘½åï¼ˆåªå«å­—æ¯/æ•°å­—/è¿å­—ç¬¦ï¼‰ã€‚\n- æ¯ä¸ª url å¿…é¡»ä»¥ https:// å¼€å¤´ä¸”å¯å…¬å¼€è®¿é—®ã€‚\n- ç¦æ­¢ä½¿ç”¨ http://ï¼›å¦‚æœæ²¡æœ‰ https ç‰ˆæœ¬ï¼Œè¯·çœç•¥è¯¥æ¡ç›®ã€‚\n- ç¦æ­¢è¿”å› data:ã€file:ã€ftp: ç­‰åè®®ã€‚\n- è‹¥æ— æ³•æ»¡è¶³ï¼Œè¯·çœç•¥æ¡ç›®ï¼›è‹¥æ— éœ€æ–‡ä»¶åˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚""",
            "file_rewrite_english": """You are enhancing a user query so it naturally references local files provided by the system.\n\nOriginal query:\n{query}\n\nAvailable local files:\n{files}\n\nWrite a rewritten query that:\n1. Remains faithful to the user's intent.\n2. References the provided file paths exactly as shown.\n3. Reads naturally in English.\n\nReturn JSON: {{\"rewritten_query\": \"<updated query>\"}}""",
            "file_rewrite_chinese": """ä½ è¦æ”¹å†™æŸ¥è¯¢ï¼Œä½¿å…¶è‡ªç„¶å¼•ç”¨ç³»ç»Ÿæä¾›çš„æœ¬åœ°æ–‡ä»¶ã€‚\n\nåŸå§‹æŸ¥è¯¢ï¼š\n{query}\nå¯ç”¨æ–‡ä»¶ï¼š\n{files}\n\nè¯·ç”Ÿæˆä¸€ä¸ªä¿æŒåŸæ„ã€è‡ªç„¶æåŠè¿™äº›æ–‡ä»¶è·¯å¾„çš„ä¸­æ–‡æŸ¥è¯¢ã€‚è¿”å› JSONï¼š{{\"rewritten_query\": \"<æ”¹å†™åçš„æŸ¥è¯¢>\"}}""",
            "fuzzify_query": """You are an expert editor who makes structured queries feel more like natural requests from humans\nwho assume shared context. Your job is to keep the userâ€™s intent intact while softening how explicitly\nit is spelled out.\n\nWORKFLOW:\n\t1.\tTake in the query fully â€” understand not just what it asks, but the voice behind it, the rhythm it follows, and the direction it leans toward.\n\t2.\tNotice where human intuition would fill the gaps instead of spelling out every point. Those are the places to smooth and simplify.\n\t3.\tLet the rewrite breathe: merge rigid bullets into an easy flow, as if explaining to a peer. Keep the same spirit and order, but let details blur into gesturesæˆ–å«è“„è¡¨è¾¾ã€‚Avoid invention; reveal less while implying more.\n\t4.\tEven when trimming or veiling specifics, make sure the reasoning thread stays intact beneath the surface â€” readable as natural language, yet still rich enough for an LLM to intuit the hidden structure or logic when needed.\n\t5.\tFor concrete requirements or illustrative examples,ä½ å¯ä»¥åœ¨è¿™äº›ä¿¡æ¯å¯¹è¯»è€…æ¥è¯´å±äºâ€œçº¦å®šä¿—æˆâ€æˆ–â€œå¯æ¨æ–­â€çš„æƒ…å†µä¸‹ï¼Œå°†å…¶æ¨¡ç³Šæˆ–çœç•¥ï¼›ä½†ä¸è¦åˆ æ‰è®©æŒ‡ä»¤å¤±å»è¿è´¯æ€§çš„å…³é”®çº¦æŸã€‚\n\t6.\tPresent the final output as a JSON block of the form {{\"analysis\": \"...\", \"fuzzy_query\": \"...\"}} â€” concise, no extras.\n\t\t- analysis should clearly describe why and how the text was softened or restructured â€” what was condensed, implied, or reframed.\n\t\t- fuzzy_query should capture the final, natural version of the query after applying the workflow â€” fluent, human-sounding, and implicitly carrying the logic of the original.\n\nRESPONSE RULES:\n- analysis: ç”¨ä¸€åˆ°ä¸¤å¥è¯è¯´æ˜åŸå§‹æ„å›¾ï¼Œå¹¶æ˜ç¡®æŒ‡å‡ºå“ªäº›ä¿¡æ¯è¢«æŠ˜å ä¸ºâ€œé»˜è®¤èƒŒæ™¯â€æˆ–â€œå¸¸è¯†â€ï¼Œä»¥åŠè¿™æ ·åšçš„åŸå› ï¼ˆå£è¯­åŒ–ã€å¼±åŒ–ç»†èŠ‚ç­‰ï¼‰ã€‚\n- fuzzy_query: ç”Ÿæˆä¸åŸæ–‡è¯­æ°”å’Œç»“æ„ä¸€è‡´çš„ç‰ˆæœ¬ï¼Œä½†åœ¨èº«ä»½ã€çº¦æŸã€èµ„æºã€ç¤ºä¾‹ç­‰å¤„ï¼Œé€šè¿‡å£è¯­åŒ–ã€çœç•¥ã€æŒ‡ä»£æˆ–è¯­æ°”ç¼“å†²ç­‰æ–¹å¼ï¼Œè¥é€ è‡ªç„¶çš„â€œçœŸå®ç”¨æˆ·å¼â€æ¨¡ç³Šï¼›æ ¸å¿ƒç›®æ ‡ä¸é€»è¾‘é¡»å®Œæ•´ä¿ç•™ã€‚\n- å¯ä¿ç•™åŸæœ‰æ®µè½æˆ–æ¡ç›®ç»“æ„ï¼Œä¹Ÿå¯åœ¨åˆç†æƒ…å†µä¸‹æ”¹å†™ä¸ºè¯´æ˜æ€§è¯­æ®µï¼›é¿å…å¼•å…¥æ–°çš„æ•°å€¼ã€è®¾å®šæˆ–å‰Šå¼±å…³é”®ç›®çš„ã€‚\n- æœ€ç»ˆè¾“å‡ºå¿…é¡»ä¸ºå•è¡Œ JSONï¼Œæ ¼å¼ä¸¥æ ¼ä¸º {{\"analysis\": \"...\", \"fuzzy_query\": \"...\"}}ï¼Œä¸å¾—åŒ…å«å¤šä½™æ–‡æœ¬æˆ– Markdownã€‚\n\nORIGINAL QUERY:\n{query}\n\nReturn ONLY the JSON object.""",
        }

        # ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™æ—§çš„é”®å
        self.templates["query_generation"] = self.templates["query_generation_english"]

    def format_file_requirement_prompt(
        self, query: str, language: str = "english"
    ) -> str:
        template_key = f"file_requirement_{language.lower()}"
        if template_key not in self.templates:
            template_key = "file_requirement_english"
        return self.get_template(template_key).format(query=query)

    def format_file_system_plan_prompt(
        self, query: str, required_items: List[str], language: str = "english"
    ) -> str:
        template_key = f"file_plan_{language.lower()}"
        if template_key not in self.templates:
            template_key = "file_plan_english"
        required_text = (
            "\n".join(f"- {item}" for item in required_items)
            if required_items
            else "(none)"
        )
        return self.get_template(template_key).format(
            query=query, required_items=required_text
        )

    def format_file_query_rewrite_prompt(
        self, query: str, files: List[Dict[str, str]], language: str = "english"
    ) -> str:
        template_key = f"file_rewrite_{language.lower()}"
        if template_key not in self.templates:
            template_key = "file_rewrite_english"
        formatted_files = "\n".join(
            f"- {file_info.get('description', '').strip() or 'File'}: {file_info.get('local_path')}"
            for file_info in files
            if file_info.get("local_path")
        )
        return self.get_template(template_key).format(
            query=query, files=formatted_files
        )

    def format_fuzzifier_prompt(self, query: str) -> str:
        return self.get_template("fuzzify_query").format(query=query)

    def _format_framework_description_block(
        self, framework_description: Optional[str], language: str
    ) -> str:
        """Format framework description block for inclusion in prompt."""
        if not framework_description:
            return ""

        if language.lower() == "chinese":
            return f"""

**âš ï¸ æ¡†æ¶é€‚é…æ€§è¦æ±‚ï¼ˆé‡è¦ï¼‰:**
ç”Ÿæˆçš„æŸ¥è¯¢å¿…é¡»ä¸¥æ ¼å‚è€ƒä¸‹è¿°æ¡†æ¶æè¿°ï¼Œç¡®ä¿æŸ¥è¯¢å†…å®¹é€‚åˆè¯¥æ¡†æ¶è§£å†³ã€‚ç”Ÿæˆçš„æ¯ä¸ªæŸ¥è¯¢éƒ½åº”è¯¥åœ¨æ¡†æ¶çš„èƒ½åŠ›èŒƒå›´å†…ï¼Œä¸è¦ç”Ÿæˆè¶…å‡ºæ¡†æ¶èƒ½åŠ›èŒƒå›´çš„ä»»åŠ¡ã€‚

- æ¡†æ¶æè¿°: {framework_description}"""
        else:
            return f"""

**âš ï¸ FRAMEWORK SUITABILITY REQUIREMENT (IMPORTANT):**
The generated queries MUST strictly reference the framework description provided below and ensure that the query content is suitable for this framework to solve. Every generated query should be within the framework's capability scope - do NOT generate tasks that are beyond the framework's abilities.

- Framework Description: {framework_description}"""

    def _format_search_context_block(
        self, search_context: Optional[Dict[str, Any]], language: str
    ) -> str:
        if not search_context:
            return ""

        results = search_context.get("results") or []
        queries = search_context.get("queries") or []
        if not results and not queries:
            return ""

        max_items = 5
        if language.lower() == "chinese":
            lines = ["- æœ€æ–°å¤–éƒ¨æ£€ç´¢æ‘˜è¦ï¼š"]
            if queries:
                lines.append("  æ£€ç´¢è¯ï¼š" + "ï¼›".join(queries[:3]))
            for idx, item in enumerate(results[:max_items], start=1):
                title = item.get("title") or "(æ— æ ‡é¢˜)"
                source = item.get("source") or ""
                date = item.get("date") or ""
                snippet = item.get("snippet") or ""
                details = title
                extras = " ".join(filter(None, [source, date])).strip()
                if extras:
                    details += f"ï¼ˆæ¥æºï¼š{extras}ï¼‰"
                lines.append(f"  {idx}. {details}")
                if snippet:
                    lines.append(f"     æ‘˜è¦ï¼š{snippet}")
            return "\n".join(lines)

        # Default to English
        lines = ["- Recent Findings from Web Search:"]
        if queries:
            lines.append("  Queries: " + ", ".join(queries[:3]))
        for idx, item in enumerate(results[:max_items], start=1):
            title = item.get("title") or "(no title)"
            source = item.get("source") or ""
            date = item.get("date") or ""
            snippet = item.get("snippet") or ""
            descriptor = title
            extras = " ".join(filter(None, [source, date])).strip()
            if extras:
                descriptor += f" â€” {extras}"
            lines.append(f"  {idx}. {descriptor}")
            if snippet:
                lines.append(f"     Summary: {snippet}")
        return "\n".join(lines)

    def get_template(self, template_name: str) -> str:
        """Get a prompt template by name"""
        return self.templates.get(template_name, "")

    def format_query_generation_prompt(
        self,
        persona: FrameworkPersona,
        tag_trace: TagTrace,
        problem_type: str,
        language: str = "english",
        search_context: Optional[Dict[str, Any]] = None,
        framework_description: Optional[str] = None,
    ) -> str:
        """Format the query generation prompt with specific context

        Args:
            persona: The framework persona
            tag_trace: TagTrace object (retained for backward compatibility but not used in prompt)
            problem_type: The specific problem type selected from the trace
            language: Language for query generation ("english" or "chinese")
            search_context: Optional web search context
            framework_description: Optional framework description from framework_config.yaml
        """
        # Select appropriate template based on language
        template_key = f"query_generation_{language.lower()}"

        # Fallback to English if language not supported
        if template_key not in self.templates:
            template_key = "query_generation_english"

        framework_desc_block = self._format_framework_description_block(
            framework_description, language
        )
        search_block = self._format_search_context_block(search_context, language)

        return self.get_template(template_key).format(
            persona=persona.get_persona(language),
            problem_type=problem_type,
            framework_description_block=framework_desc_block,
            search_context_block=search_block,
        )

    def format_persona_evaluation_prompt(
        self, persona: str, problem_type: str, language: str = "english"
    ) -> str:
        """Format the persona evaluation prompt

        Args:
            persona: The persona text to evaluate
            problem_type: The problem type to evaluate against
            language: Language for evaluation ("english" or "chinese")
        """
        template_key = f"persona_evaluation_{language.lower()}"
        if template_key not in self.templates:
            template_key = "persona_evaluation_english"

        return self.get_template(template_key).format(
            persona=persona, problem_type=problem_type
        )

    def format_persona_rewriting_prompt(
        self, persona: str, problem_type: str, language: str = "english"
    ) -> str:
        """Format the persona rewriting prompt with random detail level

        Args:
            persona: The original persona text to rewrite
            problem_type: The problem type to adapt for
            language: Language for rewriting ("english" or "chinese")
        """
        # Randomly select detail level: simple, moderate, or detailed
        import random

        detail_levels = ["simple", "moderate", "detailed"]
        detail_level = random.choice(detail_levels)

        template_key = f"persona_rewriting_{language.lower()}_{detail_level}"

        # Fallback to moderate if specific template not found
        if template_key not in self.templates:
            template_key = f"persona_rewriting_{language.lower()}_moderate"

        # Final fallback
        if template_key not in self.templates:
            template_key = "persona_rewriting_english_moderate"

        logger.info(f"Selected persona rewriting detail level: {detail_level}")

        return self.get_template(template_key).format(
            persona=persona, problem_type=problem_type
        )


class ResponseParser:
    """
    Parses LLM responses to extract structured data.
    """

    @staticmethod
    def parse_query_generation_response(
        response: str, language: str = "english"
    ) -> List[GeneratedQuery]:
        """
        Parse the query generation response to extract queries.

        Args:
            response: The LLM response text
            language: Language of the response ("english" or "chinese")
        """
        queries = []

        if language.lower() == "chinese":
            # Parse Chinese format
            queries = ResponseParser._parse_chinese_queries(response)
        else:
            # Parse English format (default)
            queries = ResponseParser._parse_english_queries(response)

        return queries

    @staticmethod
    def _parse_english_queries(response: str) -> List[GeneratedQuery]:
        """Parse English format queries"""
        queries = []

        # Extract queries
        query_pattern = r"\*\*(\w+):\*\*\s*(.*?)(?=\*\*\w+:\*\*|$)"
        query_matches = re.findall(query_pattern, response, re.DOTALL)

        # Debug: log if no matches found
        if not query_matches:
            logger.warning(
                f"No query matches found in response. Response preview: {response[:500]}..."
            )

        for difficulty, content in query_matches:
            if difficulty.upper() in ["EASY", "MEDIUM", "HARD"]:
                query = GeneratedQuery(
                    content=content.strip(),
                    difficulty=difficulty.lower(),
                    context={},
                    metadata={},
                )
                queries.append(query)

        return queries

    @staticmethod
    def _parse_chinese_queries(response: str) -> List[GeneratedQuery]:
        """Parse Chinese format queries"""
        queries = []

        # Extract Chinese queries - pattern for "**ç®€å•:**", "**ä¸­ç­‰:**", "**å›°éš¾:**"
        query_pattern = (
            r"\*\*(ç®€å•|ä¸­ç­‰|å›°éš¾):\*\*\s*(.*?)(?=\*\*(?:ç®€å•|ä¸­ç­‰|å›°éš¾):\*\*|$)"
        )
        query_matches = re.findall(query_pattern, response, re.DOTALL)

        # Debug: log if no matches found
        if not query_matches:
            logger.warning(
                f"No Chinese query matches found in response. Response preview: {response[:500]}..."
            )

        # Mapping Chinese difficulty to English
        difficulty_map = {"ç®€å•": "easy", "ä¸­ç­‰": "medium", "å›°éš¾": "hard"}

        for difficulty_chinese, content in query_matches:
            difficulty_english = difficulty_map.get(difficulty_chinese, "unknown")
            query = GeneratedQuery(
                content=content.strip(),
                difficulty=difficulty_english,
                context={},
                metadata={},
            )
            queries.append(query)

        return queries


class QueryGenerator:
    """
    Main query generation system that coordinates LLM calls, prompt formatting,
    and response parsing.
    """

    def __init__(
        self,
        llm_client: LLMClient,
        web_search_config: Optional[Dict[str, object]] = None,
    ):
        self.llm_client = llm_client
        self.prompt_manager = PromptTemplateManager()
        self.response_parser = ResponseParser()
        self.rewrite_agent = RewriteAgent(self.llm_client, self.prompt_manager)
        self.query_agent = QuerySynthesisAgent(
            llm_client=self.llm_client,
            prompt_manager=self.prompt_manager,
            response_parser=self.response_parser,
            generated_query_cls=GeneratedQuery,
            result_cls=QueryGenerationResult,
        )
        self.file_requirement_agent = FileRequirementAgent(
            self.llm_client, self.prompt_manager
        )
        self.file_system_agent = FileSystemAgent(
            llm_client=self.llm_client,
            prompt_manager=self.prompt_manager,
            base_dir=Path(__file__).parent.parent / "file_system",
        )
        self.file_augmentation_agent = FileAugmentationAgent(
            self.llm_client, self.prompt_manager
        )
        self.web_research_agent: Optional[WebResearchAgent] = None
        self.fuzzifier_agent = FuzzifierAgent(
            llm_client=self.llm_client,
            prompt_manager=self.prompt_manager,
            probability=0.0,
        )
        self.url_processing_agent = URLProcessingAgent(
            llm_client=self.llm_client, max_repair_attempts=3
        )
        self.router_agent = RouterAgent(
            rewrite_agent=self.rewrite_agent,
            web_research_agent=self.web_research_agent,
            query_agent=self.query_agent,
            requirement_agent=self.file_requirement_agent,
            file_system_agent=self.file_system_agent,
            file_augmentation_agent=self.file_augmentation_agent,
            fuzzifier_agent=self.fuzzifier_agent,
            url_processing_agent=self.url_processing_agent,
        )
        self.set_web_search_config(web_search_config)

    def set_web_search_config(self, config: Optional[Dict[str, object]]) -> None:
        """Update the web search configuration and wire the agent into the router."""
        config = config or {}
        probability = float(config.get("probability", 0.0) or 0.0)
        api_key = (
            config.get("api_key") or config.get("apiKey") or os.getenv("SERPER_API_KEY")
        )
        config.setdefault("api_key", api_key)
        config["probability"] = probability

        if probability > 0 and api_key:
            if self.web_research_agent is None:
                self.web_research_agent = WebResearchAgent(config)
            else:
                self.web_research_agent.update_config(config)
        else:
            self.web_research_agent = None

        self.router_agent.set_web_research_agent(self.web_research_agent)

    def set_fuzzifier_probability(self, probability: float) -> None:
        """Configure the fuzzifier subagent invocation probability."""
        if self.fuzzifier_agent:
            self.fuzzifier_agent.set_probability(probability)
            self.router_agent.set_fuzzifier_agent(self.fuzzifier_agent)

    def set_file_analysis_enabled(self, enabled: bool) -> None:
        """Configure whether file requirement analysis and file downloading are enabled."""
        self.router_agent.set_file_analysis_enabled(enabled)

    def set_url_processing_enabled(self, enabled: bool) -> None:
        """Configure whether URL processing (extraction, validation, repair) is enabled."""
        self.router_agent.set_url_processing_enabled(enabled)

    def _build_error_result(
        self,
        tag_trace: Optional[TagTrace],
        problem_type: str,
        language: str,
        framework_name: Optional[str],
        error_message: str,
    ) -> QueryGenerationResult:
        """Create a standardized error result for downstream consumers."""
        trace_context: List[str] = []
        if tag_trace and hasattr(tag_trace, "get_labels"):
            trace_context = tag_trace.get_labels()

        metadata = {
            "error": error_message,
            "language": language,
            "timestamp": time.time(),
        }
        if framework_name:
            metadata["framework"] = framework_name

        return QueryGenerationResult(
            queries=[],
            trace_context=trace_context,
            problem_type=problem_type,
            generation_metadata=metadata,
        )

    def generate_queries(
        self,
        persona: FrameworkPersona,
        tag_trace: TagTrace,
        problem_type: str,
        language: str = "english",
        debug_mode: bool = False,
        difficulty_distribution: Optional[Dict[str, float]] = None,
        framework_name: str = None,
        framework_description: Optional[str] = None,
    ) -> QueryGenerationResult:
        """
        Generate queries by running the configured agent workflow.
        """
        context = AgentContext(
            data={
                "persona": persona,
                "problem_type": problem_type,
                "tag_trace": tag_trace,
                "language": language,
                "debug_mode": debug_mode,
                "difficulty_distribution": difficulty_distribution,
                "framework_name": framework_name,
                "framework_description": framework_description,
            }
        )

        router_output = self.router_agent.run(context)

        if router_output.timings:
            for key, value in router_output.timings.items():
                context.add_timing(f"router.{key}", value)

        if router_output.errors:
            for error in router_output.errors:
                context.append_error(error)

        if router_output.data:
            context.update(router_output.data)

        if not router_output.success:
            error_message = "; ".join(context.errors) or "router agent failed"
            logger.error("Router agent failed: %s", error_message)
            return self._build_error_result(
                tag_trace=tag_trace,
                problem_type=problem_type,
                language=language,
                framework_name=framework_name,
                error_message=error_message,
            )

        if context.errors:
            error_message = "; ".join(context.errors)
            logger.error("Agent pipeline failed: %s", error_message)
            return self._build_error_result(
                tag_trace=tag_trace,
                problem_type=problem_type,
                language=language,
                framework_name=framework_name,
                error_message=error_message,
            )

        result: Optional[QueryGenerationResult] = context.get("query_result")
        if result is None:
            logger.error("Query synthesis agent did not return a result")
            return self._build_error_result(
                tag_trace=tag_trace,
                problem_type=problem_type,
                language=language,
                framework_name=framework_name,
                error_message="query_result missing from agent context",
            )

        metadata = result.generation_metadata
        metadata["timings"] = dict(context.timings)
        metadata.setdefault("language", language)
        metadata.setdefault("problem_type", problem_type)
        if framework_name and "framework" not in metadata:
            metadata["framework"] = framework_name

        metadata["persona_was_rewritten"] = context.get("persona_was_rewritten", False)

        search_context = context.get("search_context")
        if search_context:
            metadata["search_context"] = search_context

        downloaded_files = context.get("all_downloaded_files")
        if downloaded_files:
            file_system_info = metadata.setdefault("file_system", {})
            file_system_info["downloads"] = downloaded_files

        if context.get("persona_was_rewritten"):
            rewritten_persona = context.get("rewritten_persona")
            if isinstance(rewritten_persona, FrameworkPersona):
                metadata.setdefault("rewritten_persona", rewritten_persona.persona)
                if rewritten_persona.persona_chinese:
                    metadata.setdefault(
                        "rewritten_persona_chinese", rewritten_persona.persona_chinese
                    )

        logger.info(
            "Query generation completed with %d query(ies)", len(result.queries)
        )

        return result

    def batch_generate_queries(
        self, generation_requests: List[Dict[str, Any]], language: str = "english"
    ) -> List[QueryGenerationResult]:
        """
        Generate queries for multiple requests in batch mode.
        """
        results: List[QueryGenerationResult] = []

        for request in generation_requests:
            try:
                request_language = request.get("language", language)
                result = self.generate_queries(
                    persona=request["persona"],
                    tag_trace=request["tag_trace"],
                    problem_type=request["problem_type"],
                    language=request_language,
                    debug_mode=request.get("debug_mode", False),
                    difficulty_distribution=request.get("difficulty_distribution"),
                    framework_name=request.get("framework_name"),
                )
                results.append(result)
                time.sleep(0.1)  # Avoid rate limiting

            except Exception as exc:  # noqa: BLE001
                logger.error("Error in batch generation: %s", exc)
                results.append(
                    self._build_error_result(
                        tag_trace=request.get("tag_trace"),
                        problem_type=request.get("problem_type", ""),
                        language=request.get("language", language),
                        framework_name=request.get("framework_name"),
                        error_message=str(exc),
                    )
                )

        return results


class QueryExporter:
    """
    Exports generated queries to various formats.
    """

    @staticmethod
    def _sanitize_metadata(metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Strip internal-only fuzzifier fields before export."""
        if not metadata:
            return {}

        sanitized = copy.deepcopy(metadata)
        fuzz_meta = sanitized.get("fuzzifier")
        if isinstance(fuzz_meta, dict):
            fuzz_meta.pop("original_query", None)
        return sanitized

    @staticmethod
    def export_to_jsonl(
        results: List[QueryGenerationResult],
        output_file: Path,
        framework_name: str = None,
    ):
        """
        Export query generation results to JSONL format.

        Args:
            results: List of QueryGenerationResult objects
            output_file: Path to output JSONL file
            framework_name: Framework name to include in export (optional)
        """
        with open(output_file, "w", encoding="utf-8") as f:
            for result in results:
                for query in result.queries:
                    query_metadata = query.metadata or {}
                    fuzz_meta = query_metadata.get("fuzzifier", {})
                    sanitized_metadata = QueryExporter._sanitize_metadata(
                        query_metadata
                    )
                    combined_metadata = {
                        **sanitized_metadata,
                        **(result.generation_metadata or {}),
                    }

                    export_data = {
                        "query": query.content,
                        "difficulty": query.difficulty,
                        "trace_context": result.trace_context,
                        "problem_type": result.problem_type,
                        "requires_local_files": query_metadata.get(
                            "requires_local_files", False
                        ),
                        "used_web_search": query_metadata.get("used_web_search", False),
                        "fuzzified": bool(fuzz_meta.get("applied")),
                        "metadata": combined_metadata,
                    }
                    if fuzz_meta.get("applied") and fuzz_meta.get("original_query"):
                        export_data["original_query"] = fuzz_meta.get("original_query")
                    # Add framework field if provided
                    if framework_name:
                        export_data["framework"] = framework_name
                    f.write(json.dumps(export_data, ensure_ascii=False) + "\n")

    @staticmethod
    def export_to_json(
        results: List[QueryGenerationResult],
        output_file: Path,
        framework_name: str = None,
    ):
        """
        Export query generation results to JSON format.

        Args:
            results: List of QueryGenerationResult objects
            output_file: Path to output JSON file
            framework_name: Framework name to include in export (optional)
        """
        export_data = []

        for result in results:
            queries_payload = []
            for query in result.queries:
                query_metadata = query.metadata or {}
                fuzz_meta = query_metadata.get("fuzzifier", {})
                sanitized_metadata = QueryExporter._sanitize_metadata(query_metadata)
                entry = {
                    "content": query.content,
                    "difficulty": query.difficulty,
                    "context": query.context,
                    "requires_local_files": query_metadata.get(
                        "requires_local_files", False
                    ),
                    "used_web_search": query_metadata.get("used_web_search", False),
                    "fuzzified": bool(fuzz_meta.get("applied")),
                    "metadata": sanitized_metadata,
                }
                if fuzz_meta.get("applied") and fuzz_meta.get("original_query"):
                    entry["original_query"] = fuzz_meta.get("original_query")
                queries_payload.append(entry)

            result_data = {
                "queries": queries_payload,
                "problem_type": result.problem_type,
                "trace_context": result.trace_context,
                "generation_metadata": result.generation_metadata,
            }
            # Add framework field if provided
            if framework_name:
                result_data["framework"] = framework_name
            export_data.append(result_data)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
